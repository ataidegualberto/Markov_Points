import numpy as np
from scipy import sparse

eps = np.finfo(float).eps

class MarkovPoints:
    """
    Markov Points for State Embedding.

    This class implements the algorithms proposed on [1], which are used
    to represent the states of a Markov chain in a lower-dimensional
    space while preserving the transition probabilities between states.

    Parameters
    ----------
    P : np.ndarray or sparse.coo_matrix
        Transition probability matrix of the Markov chain. Can be a dense numpy array
        or a sparse COO matrix.
    P0 : np.ndarray
        Initial state distribution vector.
    dim : int
        The number of dimensions for the embedding space.
    neg_sampling : bool, default=True
        If True, uses negative sampling during the optimization.
    max_iter : int, default=1000
        Maximum number of iterations for the optimization algorithm.
    eta : float, default=0.001
        Learning rate for the optimization algorithm.

    Attributes
    ----------
    x : np.ndarray
        Embedding of the current states in the lower-dimensional space.
    xtil : np.ndarray
        Embedding of the next states in the lower-dimensional space.
    J : float
        Cross-entropy of the Markov model and the embedding vectors.
        It is the cost function defined in [1]:
            J = -sum(P * log2(Q)) - sum(P0 * log2(Q0))
    min_J : float
        Entropy of the Markov model. It is the minimum cross-entropy value
        that the embedding vectors may generate (ie. when x and xtil
        perfectly represent all transition and initial probabilities).
        
        It is calculated the following way:
            min_J = -sum(P * log2(P)) - sum(P0 * log2(P0))
    

    Methods
    -------
    fit():
        Performs the optimization to fit the embedding vectors to the transition probabilities.
    calculate_line_of_Q0():
        Calculates the initial probabilities Q0 based on the current embedding.
    calculate_line_of_Q(idx):
        Calculates the transition probabilities Q for a specific state based on the current embedding.
    get_line_of_P(m):
        Retrieves the transition probabilities and indices for a specific state.
    get_entropy(cross_entropy=False):
        Calculates the entropy or cross-entropy of the transition probabilities.

    Reference
    ---------
    [1]  Montalvao, Jugurta and Bastos, Gabriel and Sousa, Rodrigo and Gualberto dos Santos, AtaÃ­de Mateus,
         On the Representation of Sparse Stochastic Matrices with State Embedding.
         Available at SSRN: https://ssrn.com/abstract=4605637 or http://dx.doi.org/10.2139/ssrn.4605637 

    Examples
    --------
    >>> P = np.array([[0, 0.8, 0.2], [0.5, 0.5, 0], [0.5, 0.4, 0.1]])
    >>> P0 = np.array([9/27, 16/27, 2/27])
    >>> mkpts = MarkovPoints(P, P0, 2, False)
    >>> mkpts.fit()
    >>> print(mkpts.calculate_line_of_Q0())
    >>> for i in range(3):
    >>>     print(mkpts.calculate_line_of_Q(i))
    """

    def __init__(self,
                 P: np.ndarray | sparse.coo_matrix, 
                 P0: np.ndarray, 
                 dim: int, 
                 neg_sampling: bool = True, 
                 max_iter: int = 1000, 
                 eta: float = 0.001) -> None:
        
        self.P = P
        self.P0 = P0
        self.is_P_coo_sparse = isinstance(P, sparse.coo_matrix)
        self.dim = dim
        self.neg_sampling = neg_sampling
        self.M = len(P0)
        self.x = np.random.normal(loc=0, scale=0.01, size=(self.M, self.dim))
        self.xtil = np.random.normal(loc=0, scale=0.01, size=(self.M, self.dim))
        self.max_iter = max_iter
        self.eta = eta
        self._J = None
        self._min_J = None
        self._should_update_J = True
    
    @property
    def min_J(self) -> float:
        """
        Calculate and return the entropy of the Markov chain.

        This property computes the entropy of the Markov chain, which is the 
        minimum value of the cross-entropy between the Markov model and the 
        distributions generated by the embedding vectors.
        """


        if self._min_J is None:
            self._min_J = self.get_entropy()
        
        return self._min_J

    @property
    def J(self) -> float:
        """
        Calculate and return cost function J of the embedded Markov chain.
        """


        if self._J is None or self._should_update_J:
            self._J = self.get_entropy(cross_entropy=True)
        
        self._should_update_J = False
        return self._J

    def fit(self) -> None:
        """
        Fit the embedding to the transition and initial probabilities.

        This method optimizes the embedding of the Markov chain states to preserve the
        transition probabilities using stochastic gradient descent (SGD). It supports both
        standard SGD and SGD with negative sampling for when the Markov model is too large.
        """


        self._original_implementation()
        self._should_update_J = True

    def _original_implementation(self) -> None:
        """
        Perform the original implementation of the embedding algorithm for Markov chains.

        This method executes the original implementation of the embedding algorithm for
        Markov chains, adjusting the embeddings based on stochastic optimization techniques.
        If negative sampling is enabled, the method only uses neighbors to update
        the embeddings, sending non-neighbors away. Otherwise, it updates the embeddings
        based on all state transitions.

        The algorithm iteratively adjusts the embeddings `x` and `xtil` to minimize the 
        discrepancy between the observed transition probabilities `P` and the modeled probabilities
        `Q`. This is done through stochastic gradient descent, with different update rules depending on 
        whether negative sampling is used.
        """


        if self.neg_sampling:
            for _ in range(self.max_iter):
                M = np.random.permutation(self.M)
                for m in M:
                    P, neighbor_idxes = self.get_line_of_P(m)
                    k_non_neighbors = np.min([self.M, 3*len(P)])
                    non_neighbor_idxes = np.setdiff1d(np.arange(self.M), neighbor_idxes)[:k_non_neighbors]
                    Q0 = self.calculate_line_of_Q0()
                    Q = self.calculate_line_of_Q(m) # Just one line of Q
                    
                    # Adjustment for the a priori terms
                    w0 = self.P0[m] - Q0[m]
                    v0 = self.x[m, :]
                    u0 = v0 / np.linalg.norm(v0)
                    self.x[m, :] -= w0 * u0

                    # Adjustment of the neighbors
                    for i, n in enumerate(neighbor_idxes):
                        w = P[i] - Q[n]
                        v = self.x[m, :] - self.xtil[n, :]
                        u = v / np.linalg.norm(v)
                        delta = self.eta * w * u
                        
                        self.x[m, :] -= delta
                        self.xtil[n, :] += delta
                    

                    # Sending the non-neighbors away
                    for n in non_neighbor_idxes:
                        v = self.x[m, :] - self.xtil[n, :]
                        u = v / np.linalg.norm(v)
                        delta = -self.eta * Q[n] * u

                        self.x[m, :] -= delta
                        self.xtil[n, :] += delta

        else:
            for _ in range(self.max_iter):
                M = np.random.permutation(self.M)
                for m in M:
                    P, idxes = self.get_line_of_P(m)
                    Q0 = self.calculate_line_of_Q0()
                    Q = self.calculate_line_of_Q(m)[idxes] # Just one line of Q
                    
                    w0 = self.P0[m] - Q0[m]
                    v0 = self.x[m, :]
                    u0 = v0 / np.linalg.norm(v0)

                    dJ_dx = w0 * u0
                    dJ_dxtil = np.zeros_like(dJ_dx)
                    for n in range(idxes.shape[0]):
                        w = P[n] - Q[n]
                        v = self.x[m, :] - self.xtil[n, :]
                        u = v / np.linalg.norm(v)
                        
                        dJ_dx += w * u
                        dJ_dxtil -= w * u

                    self.x[m, :] -= self.eta * dJ_dx
                    self.xtil[m, :] -= self.eta * dJ_dxtil
        

    def calculate_Q0(self) -> np.ndarray:
        """
        Calculate the initial probabilities Q0 based on the current embedding.

        This method computes the initial probabilities Q0, which are the probabilities
        of transitioning from the initial state to each of the other states based on the
        current embedding. The probabilities are calculated using a softmax function
        applied to the negative Euclidean distances from the origin.

        Returns
        -------
        Q0 : np.ndarray
            The calculated initial probabilities based on the current embedding.
        """

        Q0 = np.exp(-np.sqrt(np.sum(self.x ** 2, axis=1)))
        return Q0 / np.sum(Q0)
    
    def calculate_line_of_Q(self, idx: int) -> np.ndarray:
        """
        Calculate the transition probabilities Q for a specific state based on the current embedding.

        This method computes the transition probabilities from a given state to all other states
        based on the current embedding. The probabilities are calculated using a softmax function
        applied to the negative Euclidean distances between the embeddings of the states.

        Parameters
        ----------
        idx : int
            The index of the state for which the transition probabilities are to be calculated.

        Returns
        -------
        Q : np.ndarray
            The calculated transition probabilities from the state with the given index to
            all other states based on the current embedding.
        """

        diff = self.x[idx, :].reshape(1, -1) - self.xtil
        d = np.sqrt(np.sum(diff**2, axis=1))
        Q = np.exp(-d)
        
        return Q / np.sum(Q)
    
    def get_line_of_P(self, m: int) -> tuple[np.ndarray, np.ndarray]:
        """
        Retrieve the transition probabilities and indices for a specific state.

        This method extracts the transition probabilities and the corresponding state indices
        from the transition probability matrix for a given state. It supports both dense
        and sparse representations of the transition probability matrix.

        Parameters
        ----------
        m : int
            Index of the state for which the transition probabilities are retrieved.

        Returns
        -------
        probabilities : np.ndarray
            Array of transition probabilities from state m.
        indices : np.ndarray
            Array of indices corresponding to the transition probabilities.
        """


        if self.is_P_coo_sparse:
            row_mask = self.P.row == m
            probabilities = self.P.data[row_mask]
            indices = self.P.col[row_mask]
        else:
            probabilities = self.P[m, :]
            indices = np.arange(self.M)

        return probabilities, indices


    def _tree_based_implementation(self) -> None:
        raise(NotImplementedError)
    

    def get_entropy(self, cross_entropy: bool = False) -> float:
        """
        Calculate the entropy or cross-entropy of the transition probabilities.

        This method computes the entropy of the transition probabilities if `cross_entropy`
        is False. If `cross_entropy` is True, it calculates the cross-entropy between the
        actual transition probabilities and the estimated probabilities based on the
        current embedding.

        Parameters
        ----------
        cross_entropy : bool, default=False
            If True, calculates the cross-entropy between the transition probabilities
            and the current embedding. If False, calculates the entropy of the transition
            probabilities.

        Returns
        -------
        H : float
            The calculated entropy or cross-entropy.

        Notes
        -----
        Entropy is a measure of the uncertainty in the transition probabilities. Cross-entropy
        measures the difference between the actual transition probabilities and the estimated
        probabilities based on the current embedding.
        """


        H = 0.0
        if cross_entropy:
            Q0 = self.calculate_Q0()
            H -= np.sum(self.P0 * np.log2(Q0 + eps))
            for i in range(self.M):
                P, idxes = self.get_line_of_P(i)
                Q = self.calculate_line_of_Q(i)
                H -= np.sum(P * np.log2(Q[idxes] + eps))
        else:
            H -= np.sum(self.P0 * np.log2(self.P0 + eps))
            for i in range(self.M):
                P, _ = self.get_line_of_P(i)
                H -= np.sum(P * np.log2(P + eps))
        
        return H


        
def mean_perplexity(P: sparse.coo_matrix | np.ndarray) -> int:
    """
    Calculate the mean perplexity of a stochastic matrix, which serves as an
    initial guess for choosing the embedding dimension.

    This function computes the mean perplexity of a given stochastic matrix `P`.
    The perplexity is derived from the entropy of the probability distribution
    and provides insight into the effective dimensionality of the data.

    Parameters
    ----------
    P : sparse.coo_matrix or np.ndarray
        The stochastic matrix representing the Markov chain. It can be a dense
        2D numpy array or a sparse COO matrix.

    Returns
    -------
    int
        The mean perplexity of the given stochastic matrix `P`, rounded to the
        nearest integer.

    Raises
    ------
    TypeError
        If the input matrix `P` is neither a 2D numpy array nor a scipy sparse COO matrix.

    Notes
    -----
    According to [1] the embedding dimension should be chosen between the
    mean perplexity and the number of states (M) in the Markov chain, depending
    on the specific problem.

    The perplexity of a probability distribution is a measure of how many
    states are effectively used. It is computed as `2` raised to the power of
    the entropy of the distribution. This measure is useful for estimating the
    intrinsic dimensionality of the data, which in turn guides the choice of
    the embedding dimension.

    Reference
    ---------
    [1]  Montalvao, Jugurta and Bastos, Gabriel and Sousa, Rodrigo and Gualberto dos Santos, AtaÃ­de Mateus,
         On the Representation of Sparse Stochastic Matrices with State Embedding.
         Available at SSRN: https://ssrn.com/abstract=4605637 or http://dx.doi.org/10.2139/ssrn.4605637 

    Example
    -------
    >>> import numpy as np
    >>> from scipy import sparse
    >>> P = np.array([[0, 0.8, 0.2], [0.5, 0.5, 0], [0.5, 0.4, 0.1]])
    >>> mean_perplexity(P)
    2
    """
    
    
    if isinstance(P, sparse.coo_matrix):
        ID = np.zeros(P.shape[0])

        for i in range(P.shape[0]):
            row_mask = P.row == i
            non_zero_probabilities = P.data[row_mask]
            H = -np.sum(non_zero_probabilities * np.log2(non_zero_probabilities + eps))
            ID[i] = 2**H

        return round(np.mean(ID))
    elif isinstance(P, np.ndarray):
        ID = np.zeros(len(P))

        for i in range(len(P)):
            
            H = -np.sum(P[i, :] * np.log2(P[i, :] + eps))
            ID[i] = 2**H
        
        return round(np.mean(ID))
    else:
        raise TypeError("The stochastic matrix P should be either a 2d numpy array or a scipy sparse coo matrix.")

if __name__ == "__main__":
    P = np.array([[0, 0.8, 0.2], [0.5, 0.5, 0], [0.5, 0.4, 0.1]])
    P0 = np.array([9/27, 16/27, 2/27])

    mkpts = MarkovPoints(P, P0, 2, False)
    print(mean_perplexity(P))
    mkpts.fit()

    print(mkpts.calculate_line_of_Q0())
    for i in range(3):
        print(mkpts.calculate_line_of_Q(i))